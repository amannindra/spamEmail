{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "from torchtext.vocab import Vocab\n",
    "from collections import Counter\n",
    "\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# # !pip3 install torch==2.3.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# # # !pip uninstall torch torchvision torchaudio -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"venky73/spam-mails-dataset\")\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/aman/.cache/kagglehub/datasets/venky73/spam-mails-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aman/.cache/kagglehub/datasets/venky73/spam-mails-dataset/versions/1/spam_ham_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "csv = os.path.join(path, \"spam_ham_dataset.csv\")\n",
    "print(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(csv):\n",
    "#     print(\"File Exists\")\n",
    "# else:\n",
    "#     print(\"File doesn't exist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4944</th>\n",
       "      <td>1396</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: meter # 1552\\r\\nrobert ,\\r\\nthere is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4690</th>\n",
       "      <td>3009</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: fw : payment\\r\\njo hillier - smith\\r\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>2025</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron / hpl actuals for november 10 -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>66</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: meter 74 , december bridgeback error\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>621</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hr performance objectives binders\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>3743</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: holiday e - cards\\r\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>3431</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: thank you for your contribution ! tog...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>2305</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron actuals for dec . 27 , 2000\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>1271</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: fw : more megan pics\\r\\n?\\r\\n- - - - ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>354</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : midcon invoices\\r\\ndo you guys a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>4478</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: innovative big sized seencs\\r\\ni know...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 label                                               text  \\\n",
       "4944        1396   ham  Subject: meter # 1552\\r\\nrobert ,\\r\\nthere is ...   \n",
       "4690        3009   ham  Subject: fw : payment\\r\\njo hillier - smith\\r\\...   \n",
       "2364        2025   ham  Subject: enron / hpl actuals for november 10 -...   \n",
       "1978          66   ham  Subject: meter 74 , december bridgeback error\\...   \n",
       "2495         621   ham  Subject: hr performance objectives binders\\r\\n...   \n",
       "...          ...   ...                                                ...   \n",
       "1748        3743  spam                     Subject: holiday e - cards\\r\\n   \n",
       "2637        3431   ham  Subject: thank you for your contribution ! tog...   \n",
       "326         2305   ham  Subject: enron actuals for dec . 27 , 2000\\r\\n...   \n",
       "4963        1271   ham  Subject: fw : more megan pics\\r\\n?\\r\\n- - - - ...   \n",
       "4459         354   ham  Subject: re : midcon invoices\\r\\ndo you guys a...   \n",
       "\n",
       "      label_num  \n",
       "4944          0  \n",
       "4690          0  \n",
       "2364          0  \n",
       "1978          0  \n",
       "2495          0  \n",
       "...         ...  \n",
       "1748          1  \n",
       "2637          0  \n",
       "326           0  \n",
       "4963          0  \n",
       "4459          0  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(csv)\n",
    "data.sample(n = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5171 entries, 0 to 5170\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  5171 non-null   int64 \n",
      " 1   label       5171 non-null   object\n",
      " 2   text        5171 non-null   object\n",
      " 3   label_num   5171 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 161.7+ KB\n",
      "------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label_num\n",
       "0  Subject: enron methanol ; meter # : 988291\\r\\n...          0\n",
       "1  Subject: hpl nom for january 9 , 2001\\r\\n( see...          0\n",
       "2  Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0\n",
       "3  Subject: photoshop , windows , office . cheap ...          1\n",
       "4  Subject: re : indian springs\\r\\nthis deal is t...          0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "\n",
    "\n",
    "print(\"------------------------\")\n",
    "\n",
    "only_text = data[[\"text\",\"label_num\"]]\n",
    "\n",
    "only_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = len(only_text) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 21, 20, 37, 19,  0, 13, 39, 38, 36, 24, 18, 17, 41, 26, 22, 30, 12,\n",
      "         9, 32,  3,  8, 28, 27, 29, 35,  7, 40, 31, 42, 38, 34,  7,  1, 41,  4,\n",
      "        25, 15, 16,  6, 37,  5, 19, 23,  2, 14, 10, 33])\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(11), tensor(21), tensor(20), tensor(37...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(3), tensor(6), tensor(2), tensor(5), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(119), tensor(151), tensor(82), tensor(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[tensor(28), tensor(42), tensor(25), tensor(9)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(29), tensor(17), tensor(33), tensor(39...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num                                          processed  \n",
       "0          0  [tensor(11), tensor(21), tensor(20), tensor(37...  \n",
       "1          0  [tensor(3), tensor(6), tensor(2), tensor(5), t...  \n",
       "2          0  [tensor(119), tensor(151), tensor(82), tensor(...  \n",
       "3          1  [tensor(28), tensor(42), tensor(25), tensor(9)...  \n",
       "4          0  [tensor(29), tensor(17), tensor(33), tensor(39...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "\n",
    "import torch\n",
    "\n",
    "def pre_processing(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    text = text.replace('subject', '')\n",
    "    \n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    \n",
    "    tokens = tokenizer(text)\n",
    "    \n",
    "    \n",
    "    vocab = {token: index for index, token in enumerate(sorted(set(tokens)))}\n",
    "    \n",
    "    encoded_text = [vocab[token] for token in tokens]\n",
    "    \n",
    "    text_tensor = torch.tensor(encoded_text)\n",
    "\n",
    "    \n",
    "    # # Numerical encoding\n",
    "    # encoded_text = [vocab[token] for token in tokens]\n",
    "      \n",
    "    return text_tensor\n",
    "  \n",
    "\n",
    "def build_vocab(text):\n",
    "  counter.update(text)\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "print(pre_processing(\"Subject: enron methanol ; meter # : 988291\\r\\nthis is a follow up to the note i gave you on monday , 4 / 3 / 00 { preliminary\\r\\nflow data provided by daren } .\\r\\nplease override pop ' s daily volume { presently zero } to reflect daily\\r\\nactivity you can obtain from gas control .\\r\\nthis change is needed asap for economics purposes .\"))\n",
    "\n",
    "data[\"processed\"] = data[\"text\"].apply(pre_processing)\n",
    "\n",
    "data[\"processed\"].apply(build_vocab)\n",
    "\n",
    "min_freq = 3\n",
    "filtered_counter = Counter({word: count for word, count in counter.items() if count >= min_freq})\n",
    "vocab = counter\n",
    "\n",
    "\n",
    "print(len(filtered_counter))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4136\n",
      "1035\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tensor(11), tensor(21), tensor(20), tensor(37...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[tensor(3), tensor(6), tensor(2), tensor(5), t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[tensor(119), tensor(151), tensor(82), tensor(...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[tensor(28), tensor(42), tensor(25), tensor(9)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[tensor(29), tensor(17), tensor(33), tensor(39...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           processed  label_num\n",
       "0  [tensor(11), tensor(21), tensor(20), tensor(37...          0\n",
       "1  [tensor(3), tensor(6), tensor(2), tensor(5), t...          0\n",
       "2  [tensor(119), tensor(151), tensor(82), tensor(...          0\n",
       "3  [tensor(28), tensor(42), tensor(25), tensor(9)...          1\n",
       "4  [tensor(29), tensor(17), tensor(33), tensor(39...          0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_train_Parameters = data.iloc[:int(0.8 * len(data))]\n",
    "\n",
    "set_test_Parameters = data.iloc[int((0.8) * len(data)):]\n",
    "\n",
    "training_data = set_train_Parameters[[\"processed\", \"label_num\"]]\n",
    "\n",
    "test_data = set_test_Parameters[[\"processed\", \"label_num\"]]\n",
    "\n",
    "training_data_no_proccess = set_train_Parameters[[\"text\", \"label_num\"]]\n",
    "\n",
    "test_data_no_proccess = set_test_Parameters[[\"text\", \"label_num\"]]\n",
    "\n",
    "\n",
    "print(len(training_data_no_proccess))\n",
    "print(len(test_data_no_proccess))\n",
    "training_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spam_count = training_data_no_proccess[\"label_num\"].value_counts()[1]\n",
    "non_spam_count = training_data_no_proccess[\"label_num\"].value_counts()[0]\n",
    "\n",
    "plt.bar([\"Spam\", \"Non-Spam\"], [spam_count, non_spam_count])\n",
    "plt.title(\"Spam vs Non-Spam\")\n",
    "plt.xlabel(\"Email Type\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([11, 21, 20, 37, 19,  0, 13, 39, 38, 36, 24, 18, 17, 41, 26, 22, 30, 12,\n",
      "         9, 32,  3,  8, 28, 27, 29, 35,  7, 40, 31, 42, 38, 34,  7,  1, 41,  4,\n",
      "        25, 15, 16,  6, 37,  5, 19, 23,  2, 14, 10, 33]), tensor(0))\n"
     ]
    }
   ],
   "source": [
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, df, text_col, label_col):\n",
    "        self.processed_texts = df[text_col].tolist()  \n",
    "        self.labels = df[label_col].tolist()\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.processed_texts)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        # Convert tokens to indices\n",
    "        tokens = self.processed_texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(tokens, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "\n",
    "\n",
    "train_datasets = SpamDataset(training_data, \"processed\", \"label_num\")\n",
    "test_datasets = SpamDataset(test_data, \"processed\", \"label_num\")\n",
    "\n",
    "print(train_datasets.__getitem__(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.rnn(embedded)\n",
    "        last_hidden = output[:, -1, :]\n",
    "        logits = self.fc(last_hidden)\n",
    "        return logits\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    # Pad sequences to the same length\n",
    "    texts_padded = torch.nn.utils.rnn.pad_sequence(texts, batch_first=True, padding_value=0)\n",
    "    labels = torch.stack(labels)\n",
    "    return texts_padded, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761072\n",
      "TextClassifier(\n",
      "  (embedding): Embedding(761072, 128)\n",
      "  (rnn): LSTM(128, 64, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, label_batch)\n\u001b[0;32m     32\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 33\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Programming\\Code\\spamEmail\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Programming\\Code\\spamEmail\\.venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Programming\\Code\\spamEmail\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    160\u001b[0m         group,\n\u001b[0;32m    161\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    166\u001b[0m         state_steps)\n\u001b[1;32m--> 168\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Programming\\Code\\spamEmail\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 318\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\Code\\spamEmail\\.venv\\Lib\\site-packages\\torch\\optim\\adam.py:443\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m--> 443\u001b[0m     \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(params[i]):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 3\n",
    "batch_size = 32\n",
    "num_classes = 2\n",
    "VOCAB_SIZE = len(vocab)\n",
    "print(VOCAB_SIZE)\n",
    "EMBED_DIM = 128\n",
    "HIDDEN_DIM = 64\n",
    "\n",
    "model = TextClassifier(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, num_classes)\n",
    "model.to(device)\n",
    "print(model)\n",
    "print(next(model.parameters()).is_cuda)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_datasets, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_datasets, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for text_batch, label_batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        text_batch = text_batch.to(device)\n",
    "        label_batch = label_batch.to(device)        \n",
    "        outputs = model(text_batch)\n",
    "        loss = criterion(outputs, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "    # for inputs in test_dataloader:\n",
    "    #     optimizer.zero_grad()\n",
    "    #     inputs = torch.LongTensor(inputs)\n",
    "    #     targets = inputs.clone()\n",
    "    #     outputs = model(inputs)\n",
    "    #     loss = criterion(outputs.view(-1, num_classes), targets.view(-1))\n",
    "    #     loss.backward()\n",
    "    #     optimizer.step()\n",
    "\n",
    "    #     total_loss += loss.item() * len(inputs)\n",
    "    #     total_samples += len(inputs)\n",
    "\n",
    "    # # Evaluate on the validation set after every epoch\n",
    "    # model.eval()\n",
    "    # total_val_loss = 0.0\n",
    "    # total_val_samples = 0\n",
    "    # with torch.no_grad():\n",
    "    #     for inputs in test_dataloader:\n",
    "    #         inputs = torch.LongTensor(inputs)\n",
    "    #         targets = inputs.clone()\n",
    "    #         outputs = model(inputs)\n",
    "    #         val_loss = criterion(outputs.view(-1, num_classes), targets.view(-1))\n",
    "\n",
    "    #         total_val_loss += val_loss.item() * len(inputs)\n",
    "    #         total_val_samples += len(inputs)\n",
    "\n",
    "    # avg_loss = total_loss / total_samples\n",
    "    # avg_val_loss = total_val_loss / total_val_samples\n",
    "\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Test Loss: 0.0198\n",
      "Accuracy: 69.47%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(next(model.parameters()).is_cuda)\n",
    "\n",
    "def test(model, test_dataloader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    test_loss /= len(test_data)\n",
    "    accuracy = 100 * correct / len(test_dataloader.dataset)\n",
    "    return test_loss, accuracy\n",
    "\n",
    "test_loss, accuracy = test(model, test_dataloader)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\amann\\.cache\\kagglehub\\datasets\\jackksoncsie\\spam-email-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jackksoncsie/spam-email-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amann\\.cache\\kagglehub\\datasets\\jackksoncsie\\spam-email-dataset\\versions\\1\\emails.csv\n"
     ]
    }
   ],
   "source": [
    "csv = os.path.join(path, \"emails.csv\")\n",
    "print(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Exists\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(csv):\n",
    "    print(\"File Exists\")\n",
    "else:\n",
    "    print(\"File doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv(csv)\n",
    "new_df = pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0970\n",
      "Accuracy: 75.63%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_data[\"processed\"] = new_data[\"text\"].apply(pre_processing)\n",
    "\n",
    "# new_data.info()\n",
    "\n",
    "procceed_new_data = new_data[[\"processed\", \"spam\"]]\n",
    "\n",
    "\n",
    "test_new_datasets = SpamDataset(procceed_new_data, \"processed\", \"spam\")\n",
    "new_test_dataLoader = DataLoader(test_new_datasets, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "test_loss, accuracy = test(model, new_test_dataLoader)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SpamDataset' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtest_datasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m()\n",
      "\u001b[31mAttributeError\u001b[39m: 'SpamDataset' object has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "test_datasets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
